{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìö DATOS MASIVOS II\n",
        "## üíª Instituto de Investigaciones en Matem√°ticas Aplicadas y en Sistemas\n",
        "## üè´ Universidad Nacional Aut√≥noma de M√©xico\n",
        "\n",
        "<hr>\n",
        "\n",
        "### üìÑ PageRank\n",
        "\n",
        "#### Realizado por:\n",
        "#### Iv√°n Alejadro Ramos Herrera\n",
        "#### üíú [@arhcoder](https://github.com/arhcoder)\n",
        "\n"
      ],
      "metadata": {
        "id": "P7F5VNFJMckc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [01] üìì Selecci√≥n de Dataset\n",
        "\n",
        "## STANFORD UNIVERSITY WEB\n",
        "### Fuente: https://snap.stanford.edu/data/web-Stanford.html\n",
        "### Informaci√≥n del dataset:\n",
        "\n",
        "> Nodes represent pages from Stanford University (stanford.edu) and directed edges represent hyperlinks between them. The data was collected in 2002.\n",
        "\n",
        "|  Dataset statistics  |      |\n",
        "|----------------------|------|\n",
        "| Nodes |\t281903 |\n",
        "| Edges |\t2312497 |\n",
        "| Nodes in largest WCC |\t255265 (0.906) |\n",
        "| Edges in largest WCC |\t2234572 (0.966) |\n",
        "| Nodes in largest SCC |\t150532 (0.534) |\n",
        "| Edges in largest SCC |\t1576314 (0.682) |\n",
        "| Average clustering coefficient |\t0.5976 |\n",
        "| Number of triangles |\t11329473 |\n",
        "| Fraction of closed triangles |\t0.002889 |\n",
        "| Diameter (longest shortest path) | 674 |\n",
        "| 90-percentile effective diameter | 9.7 |\n",
        "\n",
        "> Source (citation)\n",
        "J. Leskovec, K. Lang, A. Dasgupta, M. Mahoney. Community Structure in Large Networks: Natural Cluster Sizes and the Absence of Large Well-Defined Clusters. Internet Mathematics 6(1) 29--123, 2009. k"
      ],
      "metadata": {
        "id": "eUmJqJKuCoA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [02] üìñ Lectura del Dataset"
      ],
      "metadata": {
        "id": "VbD7gUUpcPnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creando grafo para \"Web-Stanford.txt\":\n",
        "import networkx as nx\n",
        "def load_graph(source):\n",
        "  # Crea la instancia del grafo:\n",
        "  graph = nx.DiGraph()\n",
        "\n",
        "  # Lee l√≠nea por l√≠nea el archivo de texto:\n",
        "  with open(source, \"r\") as file:\n",
        "    for line in file:\n",
        "      # Ignora las l√≠neas de comentarios:\n",
        "      if line.startswith(\"#\"):\n",
        "          continue\n",
        "      # Crea una arista para la l√≠nea le√≠da:\n",
        "      from_node, to_node = map(int, line.strip().split())\n",
        "      graph.add_edge(from_node, to_node)\n",
        "  print(f\"Grafo constru√≠do de \\\"{source}\\\"\")\n",
        "  return graph"
      ],
      "metadata": {
        "id": "BjX68XsqeKsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = load_graph(\"/content/drive/MyDrive/Datasets/Web-Stanford.txt\")"
      ],
      "metadata": {
        "id": "lkT0tUvfezsn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9bea578-1df3-4a2a-a9b9-08b649683d64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grafo constru√≠do de \"/content/drive/MyDrive/Datasets/Web-Stanford.txt\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [03] üëÆ Hit Authorities"
      ],
      "metadata": {
        "id": "QDeNGdMwfG5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Algoritmo HIT Authorities:\n",
        "def hit(graph, iterations):\n",
        "\n",
        "  # Se obtienen los nodos del grafo;\n",
        "  # Y se inicializan los HUBS y Authorities:\n",
        "  nodes = list(graph.nodes)\n",
        "  hubs = {node: 1.0 for node in nodes}\n",
        "  authorities = {node: 1.0 for node in nodes}\n",
        "  for _ in range(iterations):\n",
        "    normalization = 0\n",
        "\n",
        "    # Se actualizan los valores de \"authorities\":\n",
        "    new_authorities = {}\n",
        "    for node in nodes:\n",
        "      new_authoritie = sum(hubs[neighbor] for neighbor in graph.predecessors(node))\n",
        "      new_authorities[node] = new_authoritie\n",
        "      normalization += new_authoritie**2\n",
        "    normalization = normalization**0.5\n",
        "\n",
        "    # Normaliza los \"Authorities\":\n",
        "    for node in nodes:\n",
        "      authorities[node] = new_authorities[node] / normalization\n",
        "\n",
        "    # Se actualizan los hubs:\n",
        "    new_hubs = {}\n",
        "    for node in nodes:\n",
        "      new_hub = sum(authorities[neighbor] for neighbor in graph.successors(node))\n",
        "      new_hubs[node] = new_hub\n",
        "      normalization += new_hub**2\n",
        "    normalization = normalization**0.5\n",
        "\n",
        "    # Normaliza los HUBS:\n",
        "    for node in nodes:\n",
        "      hubs[node] = new_hubs[node] / normalization\n",
        "\n",
        "  return hubs, authorities"
      ],
      "metadata": {
        "id": "-zy3W_KUfXoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hubs, authorities = hit(graph, 100)"
      ],
      "metadata": {
        "id": "bkinCJGngzxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [04] üèÖ PageRank"
      ],
      "metadata": {
        "id": "T777I-B3g_7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Algoritmo PageRank:\n",
        "def pagerank(graph, iterations, damp, min_error):\n",
        "\n",
        "  # Se obtienen los nodos del grafo;\n",
        "  # Y se inicializa el PageRank:\n",
        "  nodes = list(graph.nodes)\n",
        "  pagerank = {node: 1 / len(nodes) for node in nodes}\n",
        "\n",
        "  for _ in range(iterations):\n",
        "    new_pagerank = {}\n",
        "    for node in nodes:\n",
        "      new_pagerank[node] = (1 - damp) / len(nodes)\n",
        "      predecessors = list(graph.predecessors(node))\n",
        "      if predecessors:\n",
        "        new_pagerank[node] += damp * sum(pagerank[neighbor] / len(predecessors) for neighbor in predecessors)\n",
        "\n",
        "    # Si el algoritmo converge:\n",
        "    difference = sum(abs(new_pagerank[node] - pagerank[node]) for node in nodes)\n",
        "    if difference < min_error:\n",
        "      break\n",
        "    pagerank = new_pagerank\n",
        "\n",
        "  return pagerank"
      ],
      "metadata": {
        "id": "yNxvW9HYhDMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pagerank = pagerank(graph, 100, 0.80, 0.000001)"
      ],
      "metadata": {
        "id": "cwTdwPpbir-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [05] üèÜ TOPS"
      ],
      "metadata": {
        "id": "3u0hrpc8j--n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtiene los TOP 6 de los resultados obtenidos:\n",
        "top_hubs = sorted(hubs.items(), key=lambda x: x[1], reverse=True)[:6]\n",
        "top_authorities = sorted(authorities.items(), key=lambda x: x[1], reverse=True)[:6]\n",
        "top_pagerank = sorted(pagerank.items(), key=lambda x: x[1], reverse=True)[:6]"
      ],
      "metadata": {
        "id": "3nHofuQElKzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resultados de los algoritmos:\n",
        "print(\"STANFORD WEB\")\n",
        "print(\"Top 6 Hubs:\")\n",
        "top = 1\n",
        "for node, score in top_hubs:\n",
        "  print(f\" *  üèÖ [{top}] NODO {node}:\\t\\t{score}\")\n",
        "  top += 1\n",
        "\n",
        "print(\"\\nTop 6 Autoridades:\")\n",
        "top = 1\n",
        "for node, score in top_authorities:\n",
        "  print(f\" *  üèÖ [{top}] NODO {node}:\\t\\t{score}\")\n",
        "  top += 1\n",
        "\n",
        "print(\"\\nTop 6 PageRank:\")\n",
        "top = 1\n",
        "for node, score in top_pagerank:\n",
        "  print(f\" *  üèÖ [{top}] NODO {node}:\\t\\t{score}\")\n",
        "  top += 1"
      ],
      "metadata": {
        "id": "5jDiKGoZkWZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee59635-1d46-4802-9c3c-24abed2d081c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STANFORD WEB\n",
            "Top 6 Hubs:\n",
            " *  üèÖ [1] NODO 97968:\t\t0.007248244672640702\n",
            " *  üèÖ [2] NODO 193259:\t\t0.007247703133953272\n",
            " *  üèÖ [3] NODO 275047:\t\t0.007247055737364494\n",
            " *  üèÖ [4] NODO 102208:\t\t0.007246705100859477\n",
            " *  üèÖ [5] NODO 151695:\t\t0.007245988120260295\n",
            " *  üèÖ [6] NODO 31061:\t\t0.007245745286066946\n",
            "\n",
            "Top 6 Autoridades:\n",
            " *  üèÖ [1] NODO 226411:\t\t0.34858469969464767\n",
            " *  üèÖ [2] NODO 234704:\t\t0.31713641659190894\n",
            " *  üèÖ [3] NODO 105607:\t\t0.312541229456666\n",
            " *  üèÖ [4] NODO 198090:\t\t0.311606426760691\n",
            " *  üèÖ [5] NODO 81435:\t\t0.3115992528680128\n",
            " *  üèÖ [6] NODO 214128:\t\t0.31158930825968234\n",
            "\n",
            "Top 6 PageRank:\n",
            " *  üèÖ [1] NODO 3408:\t\t3.547319468044002e-06\n",
            " *  üèÖ [2] NODO 91620:\t\t3.54731946804399e-06\n",
            " *  üèÖ [3] NODO 192935:\t\t3.54731946804399e-06\n",
            " *  üèÖ [4] NODO 14356:\t\t3.5473194680439866e-06\n",
            " *  üèÖ [5] NODO 133133:\t\t3.5473194680439824e-06\n",
            " *  üèÖ [6] NODO 167251:\t\t3.5473194680439824e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [06] üó∫Ô∏è Map Reduce\n",
        "**FUENTE:** https://medium.com/datable/beginners-guide-for-mapreduce-with-mrjob-in-python-dbd2e7dd0f86\n",
        "\n",
        "<br>\n",
        "\n",
        "**‚ö†Ô∏è NOTA:** ESTE C√ìDIGO EST√Å PARCIALMENTE TOMADO DE INTERNET, Y NO CORRE EN COLAB, YA QUE EST√Å DISE√ëADO PARA ENTORNOS CON HADOOP U OTRO TIPO DE PROCESAMIENTO DISTRIBU√çDO."
      ],
      "metadata": {
        "id": "-KIp3hi0mNaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqu√≠ s√≠ voy a usar una librer√≠a, no me sale el Map Reduce:\n",
        "!pip install mrjob"
      ],
      "metadata": {
        "id": "yiPGXbAJmQmn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ccdf27-696a-41c4-811c-67e277ab8165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mrjob\n",
            "  Downloading mrjob-0.7.4-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m439.6/439.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from mrjob) (6.0.1)\n",
            "Installing collected packages: mrjob\n",
            "Successfully installed mrjob-0.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PageRank con MapReduce:\n",
        "# AGRADECIMIENTOS A Vicky Bee Wu, sin su c√≥digo no habr√≠a podido lograr esta secci√≥n:\n",
        "# https://medium.com/datable/beginners-guide-for-mapreduce-with-mrjob-in-python-dbd2e7dd0f86\n",
        "from mrjob.job import MRJob\n",
        "\n",
        "class PageRankMR(MRJob):\n",
        "  def configure_args(self):\n",
        "    super(PageRankMR, self).configure_args()\n",
        "    self.add_passthru_arg(\"--damping-factor\", default=0.85, type=float, help=\"Damping factor for PageRank\")\n",
        "\n",
        "  # MAP:\n",
        "  def mapper(self, _, node):\n",
        "    # PageRank para cada Nodo:\n",
        "    yield node, 1.0\n",
        "\n",
        "    # Distribuye el PageRank a los nodos vecinos:\n",
        "    neighbors = list(self.options.graph.neighbors(node))\n",
        "    if neighbors:\n",
        "      pagerank = 1 / len(neighbors)\n",
        "      for neighbor in neighbors:\n",
        "        yield neighbor, pagerank\n",
        "\n",
        "  # REDUCE:\n",
        "  def reducer(self, node, values):\n",
        "    damping_factor = self.options.damping_factor\n",
        "    new_pagerank = (1 - damping_factor) + damping_factor * sum(values)\n",
        "    yield node, new_pagerank"
      ],
      "metadata": {
        "id": "avvUTkLOpAJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementa PageRank MapReduce con el grafo de Stanford:\n",
        "PageRankMR.graph = graph\n",
        "PageRankMR.run()"
      ],
      "metadata": {
        "id": "ph7Mg0KipN6i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "da8403d2-43bf-4305-9fa5-b1720f282132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [options] [input files]\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [08] üíú @arhcoder\n",
        "## Realizado por:\n",
        "### Iv√°n Alejadro Ramos Herrera\n",
        "### üíú [@arhcoder](https://github.com/arhcoder)"
      ],
      "metadata": {
        "id": "4DinJz64wzft"
      }
    }
  ]
}